import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
import joblib
import os

# Function to load and preprocess data
def load_and_preprocess_data(file_path):
    """
    Loads data from a CSV file, converts 'open_time' to datetime,
    sets it as index, selects relevant columns, and drops NA values.
    """
    data = pd.read_csv(file_path)
    data['open_time'] = pd.to_datetime(data['open_time'])
    data.set_index('open_time', inplace=True)
    data = data[['open', 'high', 'low', 'close', 'volume']]
    data.dropna(inplace=True)
    return data

# Function to resample data to different timeframes
def resample_data(data, timeframe):
    """
    Resamples the data to the specified timeframe and aggregates OHLCV.
    """
    tf_data = data.resample(timeframe).agg({
        'open': 'first',
        'high': 'max',
        'low': 'min',
        'close': 'last',
        'volume': 'sum'
    }).dropna()
    return tf_data

# Function to add technical indicators (including ATR)
def add_technical_indicators(data):
    """
    Adds SMA, RSI, Bollinger Bands, and ATR to the dataframe.
    """
    # Simple Moving Average
    data['SMA'] = data['close'].rolling(window=14).mean()

    # Relative Strength Index
    delta = data['close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    data['RSI'] = 100 - (100 / (1 + rs))

    # Bollinger Bands
    data['Bollinger_Upper'] = data['close'].rolling(window=20).mean() + 2 * data['close'].rolling(window=20).std()

    # Average True Range (ATR)
    high_low = data['high'] - data['low']
    high_close = np.abs(data['high'] - data['close'].shift())
    low_close = np.abs(data['low'] - data['close'].shift())
    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1, skipna=False) # Ensure TR is calculated correctly
    data['ATR'] = tr.rolling(window=14).mean()

    data.dropna(inplace=True) # Drop rows with NaN values created by indicators
    return data

# Creating Sequences
def create_sequences(data, seq_length):
    """
    Creates sequences of data for LSTM/GRU input.
    'close' price (first column) is the target variable.
    """
    X, y = [], []
    if len(data) <= seq_length: # Check if data is long enough
        return np.array(X), np.array(y)
    for i in range(seq_length, len(data)):
        X.append(data[i-seq_length:i])
        y.append(data[i, 0])  # Target is the first column ('close')
    return np.array(X), np.array(y)

# Function to build the LSTM model with tanh
def build_lstm_model(input_shape):
    """
    Builds an LSTM model with tanh activation.
    """
    lstm_model = Sequential([
        LSTM(64, activation='tanh', return_sequences=True, input_shape=input_shape),
        Dropout(0.2),
        LSTM(64, activation='tanh', return_sequences=False),
        Dropout(0.2),
        Dense(32, activation='tanh'),
        Dense(1)  # Linear activation for regression output
    ])
    lstm_model.compile(optimizer='adam', loss='mse')
    return lstm_model

# Function to build the GRU model with tanh
def build_gru_model(input_shape):
    """
    Builds a GRU model with tanh activation.
    """
    gru_model = Sequential([
        GRU(64, activation='tanh', return_sequences=True, input_shape=input_shape),
        Dropout(0.2),
        GRU(64, activation='tanh', return_sequences=False),
        Dropout(0.2),
        Dense(32, activation='tanh'),
        Dense(1)  # Linear activation for regression output
    ])
    gru_model.compile(optimizer='adam', loss='mse')
    return gru_model

# Function to train the model
def train_model(model, X_train, y_train, X_val, y_val, epochs=100, batch_size=64, model_save_path='best_model.keras'):
    """
    Trains the model with early stopping, learning rate reduction, and model checkpointing.
    """
    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)
    model_checkpoint = ModelCheckpoint(model_save_path, monitor='val_loss', save_best_only=True, verbose=1)

    history = model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=epochs,
        batch_size=batch_size,
        callbacks=[early_stopping, reduce_lr, model_checkpoint],
        verbose=1
    )
    return model, history

# Function to evaluate the model
def evaluate_model(model, X_test, y_test, scaler):
    """
    Evaluates the model on test data and returns metrics.
    """
    predictions = model.predict(X_test)
    num_features = scaler.n_features_in_

    # Rescale predictions
    dummy_preds = np.zeros((predictions.shape[0], num_features))
    dummy_preds[:, 0] = predictions.reshape(-1)  # Predictions for the first feature ('close')
    predictions_rescaled = scaler.inverse_transform(dummy_preds)[:, 0]

    # Rescale actual y_test values
    dummy_y_test = np.zeros((y_test.shape[0], num_features))
    dummy_y_test[:, 0] = y_test.reshape(-1) # Actual values for the first feature ('close')
    y_test_rescaled = scaler.inverse_transform(dummy_y_test)[:, 0]

    mse = mean_squared_error(y_test_rescaled, predictions_rescaled)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test_rescaled, predictions_rescaled)
    r2 = r2_score(y_test_rescaled, predictions_rescaled)
    next_predicted_price = predictions_rescaled[-1] if len(predictions_rescaled) > 0 else np.nan

    return y_test_rescaled, predictions_rescaled, mse, rmse, mae, r2, next_predicted_price

# Function to save the trained model
def save_trained_model(model, model_type, timeframe):
    """
    Saves the trained model to a file.
    """
    model_filename = f'model_{model_type}_{timeframe}.keras'
    model.save(model_filename)
    print(f"Model for {model_type} at {timeframe} saved as {model_filename}")

# Function to plot results for each timeframe
def plot_results(y_test_rescaled, predictions_rescaled, model_type, timeframe, dates):
    """
    Plots actual vs. predicted prices.
    """
    plt.figure(figsize=(12, 6))
    plt.plot(dates, y_test_rescaled, label='Real Prices')
    plt.plot(dates, predictions_rescaled, label='Predicted Prices', linestyle='--')
    plt.title(f'{model_type} Model - {timeframe} Price Prediction')
    plt.xlabel('Time')
    plt.ylabel('Price')
    plt.legend()
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout() # Adjust layout to prevent labels from overlapping
    plt.savefig(f'{model_type}_{timeframe}_prediction.png')
    plt.show()

# Function to plot comparison of evaluation metrics
def plot_metrics_comparison(results):
    """
    Plots a bar chart comparing evaluation metrics for different models and timeframes.
    """
    timeframes = list(results.keys())
    if not timeframes:
        print("No results to plot for metrics comparison.")
        return

    metrics = ['MSE', 'RMSE', 'MAE', 'RÂ²']
    model_types = list(results[timeframes[0]].keys()) # Get model types from the first timeframe

    metric_values = {metric: {model_type: [] for model_type in model_types} for metric in metrics}

    for tf in timeframes:
        for model_type in model_types:
            if model_type in results[tf]:
                for metric in metrics:
                    metric_values[metric][model_type].append(results[tf][model_type].get(metric, np.nan))
            else: # Handle missing model results for a timeframe
                 for metric in metrics:
                    metric_values[metric][model_type].append(np.nan)


    num_models = len(model_types)
    bar_width = 0.8 / num_models # Adjust bar width based on number of models
    
    plt.figure(figsize=(15, 12)) # Adjusted figure size
    for i, metric in enumerate(metrics):
        plt.subplot(2, 2, i + 1)
        x_pos_base = np.arange(len(timeframes))

        for j, model_type in enumerate(model_types):
            # Calculate offset for each model's bars
            offset = (j - (num_models - 1) / 2) * bar_width
            bars = plt.bar(x_pos_base + offset, metric_values[metric][model_type], bar_width, label=model_type)
            # Add text labels on bars
            for bar in bars:
                yval = bar.get_height()
                if not np.isnan(yval):
                    plt.text(bar.get_x() + bar.get_width()/2.0, yval, f'{yval:.2f}', va='bottom', ha='center')


        plt.title(f'{metric} Comparison')
        plt.xlabel('Timeframe')
        plt.ylabel(metric)
        plt.xticks(x_pos_base, timeframes)
        plt.legend()
        plt.grid(axis='y', linestyle='--')


    plt.tight_layout()
    plt.savefig('metrics_comparison.png')
    plt.show()

# Main function to execute all steps
def main():
    """
    Main function to run the stock price prediction pipeline.
    """
    file_path = '/content/drive/MyDrive/binance_data_20180101_to_20241229.csv' # Update with your file path
    # Check if file exists
    if not os.path.exists(file_path):
        print(f"Error: Data file not found at {file_path}")
        print("Please ensure the file path is correct and you have mounted Google Drive if using Colab.")
        return

    timeframes = {'1h': '1 Hour', '4h': '4 Hours', '1d': '1 Day'}
    seq_length = 50  # Sequence length for LSTM/GRU
    results = {}     # To store evaluation results

    # Load initial data
    base_data = load_and_preprocess_data(file_path)
    if base_data.empty:
        print("No data loaded. Exiting.")
        return

    for tf_key, tf_name in timeframes.items():
        print(f"\nProcessing timeframe: {tf_name} ({tf_key})")
        results[tf_name] = {}

        # Resample and add indicators
        tf_data_processed = resample_data(base_data.copy(), tf_key) # Use a copy to avoid modifying base_data
        if tf_data_processed.empty:
            print(f"No data after resampling for {tf_name}. Skipping.")
            continue
        
        tf_data_with_indicators = add_technical_indicators(tf_data_processed)
        if tf_data_with_indicators.empty:
            print(f"No data after adding technical indicators for {tf_name}. Skipping.")
            continue

        # Define feature columns, ensuring 'close' is first for y and evaluation
        feature_cols = ['close', 'open', 'high', 'low', 'volume', 'SMA', 'RSI', 'Bollinger_Upper', 'ATR']
        
        # Ensure all feature columns exist
        missing_cols = [col for col in feature_cols if col not in tf_data_with_indicators.columns]
        if missing_cols:
            print(f"Missing columns for {tf_name}: {missing_cols}. Skipping.")
            continue
            
        tf_data_ordered = tf_data_with_indicators[feature_cols]
        features_np = tf_data_ordered.values

        # 1. Split features *before* normalization
        train_split_idx = int(0.8 * len(features_np))
        val_split_idx = train_split_idx + int(0.1 * len(features_np))

        train_features = features_np[:train_split_idx]
        val_features = features_np[train_split_idx:val_split_idx]
        test_features = features_np[val_split_idx:]

        if not (len(train_features) > seq_length and len(val_features) > seq_length and len(test_features) > seq_length):
            print(f"Insufficient data for train/val/test split after considering seq_length for {tf_name}. Skipping.")
            continue

        # 2. Normalize data (Fit only on train, transform all)
        scaler = MinMaxScaler(feature_range=(0, 1))
        
        # Fit ONLY on train_features and transform it
        train_data_normalized = scaler.fit_transform(train_features)
        
        # Transform val and test features using the *fitted* scaler
        val_data_normalized = scaler.transform(val_features)
        test_data_normalized = scaler.transform(test_features)

        # 3. Save the scaler
        scaler_path = f'scaler_{tf_key}.pkl'
        joblib.dump(scaler, scaler_path)
        print(f"Scaler for {tf_name} saved to {scaler_path}")

        # Create sequences for each split
        X_train, y_train = create_sequences(train_data_normalized, seq_length)
        X_val, y_val = create_sequences(val_data_normalized, seq_length)
        X_test, y_test = create_sequences(test_data_normalized, seq_length)

        # Check if we have enough data to proceed after creating sequences
        if X_train.shape[0] == 0 or X_val.shape[0] == 0 or X_test.shape[0] == 0:
            print(f"Skipping {tf_name} due to insufficient data after creating sequences.")
            continue
        
        # Prepare dates for plotting (align with y_test)
        # The dates should correspond to the start of the test_features, adjusted for seq_length
        test_dates_start_index = val_split_idx + seq_length
        dates_for_plot = tf_data_ordered.index[test_dates_start_index : test_dates_start_index + len(y_test)]

        if len(dates_for_plot) != len(y_test):
            print(f"Warning: Mismatch between dates ({len(dates_for_plot)}) and y_test ({len(y_test)}) in {tf_name}. Plotting might be affected.")
            # Fallback if lengths don't match, though ideally they should
            dates_for_plot = tf_data_ordered.index[val_split_idx + seq_length : val_split_idx + seq_length + len(y_test)]


        # --- LSTM Model ---
        print(f"\n--- Training LSTM Model for {tf_name} ---")
        lstm_model_path = f'best_lstm_model_{tf_key}.keras'
        lstm_model = build_lstm_model((X_train.shape[1], X_train.shape[2]))
        lstm_model, _ = train_model(lstm_model, X_train, y_train, X_val, y_val, epochs=100, model_save_path=lstm_model_path) # 100 epochs, can be adjusted
        
        print(f"--- Evaluating LSTM Model for {tf_name} ---")
        y_test_r_lstm, preds_r_lstm, mse_l, rmse_l, mae_l, r2_l, next_p_l = evaluate_model(lstm_model, X_test, y_test, scaler)
        results[tf_name]['LSTM'] = {'MSE': mse_l, 'RMSE': rmse_l, 'MAE': mae_l, 'RÂ²': r2_l, 'Next Predicted Price': next_p_l}
        save_trained_model(lstm_model, 'LSTM', tf_key)
        if len(dates_for_plot) == len(y_test_r_lstm):
             plot_results(y_test_r_lstm, preds_r_lstm, 'LSTM', tf_name, dates_for_plot)
        else:
            print(f"Skipping LSTM plot for {tf_name} due to date/prediction length mismatch.")


        # --- GRU Model ---
        print(f"\n--- Training GRU Model for {tf_name} ---")
        gru_model_path = f'best_gru_model_{tf_key}.keras'
        gru_model = build_gru_model((X_train.shape[1], X_train.shape[2]))
        gru_model, _ = train_model(gru_model, X_train, y_train, X_val, y_val, epochs=100, model_save_path=gru_model_path) # 100 epochs
        
        print(f"--- Evaluating GRU Model for {tf_name} ---")
        y_test_r_gru, preds_r_gru, mse_g, rmse_g, mae_g, r2_g, next_p_g = evaluate_model(gru_model, X_test, y_test, scaler)
        results[tf_name]['GRU'] = {'MSE': mse_g, 'RMSE': rmse_g, 'MAE': mae_g, 'RÂ²': r2_g, 'Next Predicted Price': next_p_g}
        save_trained_model(gru_model, 'GRU', tf_key)
        if len(dates_for_plot) == len(y_test_r_gru):
            plot_results(y_test_r_gru, preds_r_gru, 'GRU', tf_name, dates_for_plot)
        else:
            print(f"Skipping GRU plot for {tf_name} due to date/prediction length mismatch.")


    # Display evaluation metrics
    print("\n--- Comparison of Evaluation Metrics ---")
    for tf_name_res, metrics_res in results.items():
        print(f"\nTimeframe: {tf_name_res}")
        for model_name, metrics_values in metrics_res.items():
            print(f"  Model: {model_name}")
            print(f"    MSE: {metrics_values.get('MSE', float('nan')):.2f}")
            print(f"    RMSE: {metrics_values.get('RMSE', float('nan')):.2f}")
            print(f"    MAE: {metrics_values.get('MAE', float('nan')):.2f}")
            print(f"    RÂ²: {metrics_values.get('RÂ²', float('nan')):.2f}")
            print(f"    Next Predicted Price: {metrics_values.get('Next Predicted Price', float('nan')):.2f}")

    # Plot metrics comparison
    plot_metrics_comparison(results)
    print("\nProcessing complete.")

if __name__ == '__main__':
    # To run in Google Colab, ensure you mount your drive first if file_path is in Drive
    # from google.colab import drive
    # drive.mount('/content/drive')
    main()
